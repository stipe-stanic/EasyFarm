{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install torchsummary"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-21T18:20:00.384800Z",
     "iopub.execute_input": "2023-05-21T18:20:00.385161Z",
     "iopub.status.idle": "2023-05-21T18:20:14.621939Z",
     "shell.execute_reply.started": "2023-05-21T18:20:00.385131Z",
     "shell.execute_reply": "2023-05-21T18:20:14.620798Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n\u001B[0m",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "import torchsummary\n",
    "import torchvision.transforms\n",
    "import seaborn as sns\n",
    "\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets.folder import default_loader, DatasetFolder\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from joblib import dump"
   ],
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "id": "ECQHPsJgzOTN",
    "execution": {
     "iopub.status.busy": "2023-05-21T18:20:14.624848Z",
     "iopub.execute_input": "2023-05-21T18:20:14.625149Z",
     "iopub.status.idle": "2023-05-21T18:20:24.009456Z",
     "shell.execute_reply.started": "2023-05-21T18:20:14.625122Z",
     "shell.execute_reply": "2023-05-21T18:20:24.008430Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Custom ImageFolder class\n",
    "\n",
    "def valid_file(filename: str) -> bool:\n",
    "    \"\"\"Check if current file has valid extension\"\"\"\n",
    "\n",
    "    return filename.lower().endswith(('.jpg', '.png'))\n",
    "\n",
    "\n",
    "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "    \"\"\"Finds the class folders in a dataset.\n",
    "\n",
    "    This function searches for subdirectories in the specified directory and returns a list of class names and\n",
    "    dictionary mapping each class name to its corresponding index.\n",
    "\n",
    "    The function only includes subdirectories whose names match the regular expression 'apple'. This is intended to\n",
    "    filter the classes for a specific type of dataset.\n",
    "\n",
    "    :param directory: The root directory of the training dataset.\n",
    "\n",
    "    :returns: A tuple containing a list of strings where each string is the name of a class folder and dictionary\n",
    "    that maps each class name to its corresponding index.\n",
    "\n",
    "    :raises FileNotFoundError: If no class folders are found in the specified directory.\n",
    "    \"\"\"\n",
    "\n",
    "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir()\n",
    "                     and re.search('apple', entry.name))\n",
    "    if not classes:\n",
    "        raise FileNotFoundError(f\"Couldn't find any class folder in {directory}.\")\n",
    "\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "    return classes, class_to_idx\n",
    "\n",
    "\n",
    "class CustomImageFolder(torchvision.datasets.DatasetFolder):\n",
    "    \"\"\" Implements custom ImageFolder class that overrides DatasetFolder methods, so it's possible to load only\n",
    "    specific subdirectories(classes) of the directory instead of the whole directory.\n",
    "\n",
    "    Enables two valid extensions (.jpg, .png)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, transform=None, target_transform=None, loader=default_loader, is_valid_file=valid_file):\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform, loader=loader, is_valid_file=is_valid_file)\n",
    "    def find_classes(self, directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "        return find_classes(directory)"
   ],
   "metadata": {
    "id": "0G_DNBG9zOTP",
    "execution": {
     "iopub.status.busy": "2023-05-21T18:20:24.010872Z",
     "iopub.execute_input": "2023-05-21T18:20:24.011604Z",
     "iopub.status.idle": "2023-05-21T18:20:24.023363Z",
     "shell.execute_reply.started": "2023-05-21T18:20:24.011566Z",
     "shell.execute_reply": "2023-05-21T18:20:24.022498Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Visualization\n",
    "\n",
    "def show_dataset(dataset: DatasetFolder | Subset, n=6) -> None:\n",
    "    \"\"\"Shows grid of images as a single image\n",
    "\n",
    "    :param dataset: Loaded torchvision dataset\n",
    "    :param n: Number of rows and columns\n",
    "    \"\"\"\n",
    "\n",
    "    # Transform image from tensor to PILImage\n",
    "    transform = torchvision.transforms.ToPILImage()\n",
    "    img = np.vstack([np.hstack([np.asarray(transform(dataset[i][0])) for _ in range(n)])\n",
    "                     for i in range(n)])\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_batch(dataset_loader: DataLoader , num_of_images: int = 9) -> None:\n",
    "    \"\"\"Displays images before feeding them to the model\n",
    "\n",
    "    :raises AssertionError: If number of images to display exceeds batch size\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = dataset_loader.batch_size\n",
    "\n",
    "    try:\n",
    "        assert num_of_images < batch_size,\\\n",
    "            f\"Number of images to display exceeds batch size: {num_of_images} > {batch_size}\"\n",
    "\n",
    "        data_iter = iter(dataset_loader)\n",
    "        images, labels = next(data_iter)\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        transform = torchvision.transforms.ToPILImage()\n",
    "        for i in range(num_of_images):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            img = np.asarray(transform(images[i]))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    except AssertionError as msg:\n",
    "        print(\"Error:\", msg)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_test, y_pred, class_names):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, display_labels=class_names, xticks_rotation=\"vertical\",\n",
    "                                        ax=ax, colorbar=False)\n",
    "    plt.show(block=False)"
   ],
   "metadata": {
    "id": "-tj08VW9zOTQ",
    "execution": {
     "iopub.status.busy": "2023-05-21T18:20:24.025985Z",
     "iopub.execute_input": "2023-05-21T18:20:24.026386Z",
     "iopub.status.idle": "2023-05-21T18:20:24.039396Z",
     "shell.execute_reply.started": "2023-05-21T18:20:24.026355Z",
     "shell.execute_reply": "2023-05-21T18:20:24.038375Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Utils\n",
    "\n",
    "def loader_shape(dataset_loader: DataLoader) -> Tuple[torch.Size, torch.Size]:\n",
    "    \"\"\"Prints shape of loaded dataset\n",
    "\n",
    "    :returns: Tuple of tensor shapes (images, labels)\n",
    "    \"\"\"\n",
    "\n",
    "    data_iter = iter(dataset_loader)\n",
    "    images, labels = next(data_iter)\n",
    "\n",
    "    return images.shape, labels.shape\n",
    "\n",
    "\n",
    "def get_device() -> torch.device:\n",
    "    cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "    return device\n",
    "\n",
    "\n",
    "def stratify_split(dataset: CustomImageFolder) -> Tuple[Subset, Subset, Subset]:\n",
    "    train_size = int(len(dataset) * 0.8)\n",
    "    val_size = int(len(dataset) * 0.1)\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    # Split the dataset -> using sklearn split method with stratify\n",
    "    targets = np.array(dataset.targets)\n",
    "    train_idx, temp_idx = train_test_split(\n",
    "        np.arange(len(dataset)),\n",
    "        test_size=val_size + test_size,\n",
    "        shuffle=True,\n",
    "        stratify=targets,\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    val_idx, test_idx = train_test_split(\n",
    "        temp_idx,\n",
    "        test_size=test_size,\n",
    "        shuffle=True,\n",
    "        stratify=targets[temp_idx],\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    train_dataset = Subset(dataset, train_idx)\n",
    "    val_dataset = Subset(dataset, val_idx)\n",
    "    test_dataset = Subset(dataset, test_idx)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "\n",
    "def print_class_distribution(dataset: DatasetFolder, train_dataset: Subset, val_dataset: Subset, test_dataset: Subset) -> None:\n",
    "    # Check distribution of classes in train, val and test datasets\n",
    "    train_target_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_target_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_target_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    train_targets = []\n",
    "    for batch in train_target_loader:\n",
    "        train_targets.extend(batch[1].tolist())\n",
    "\n",
    "    val_targets = []\n",
    "    for batch in val_target_loader:\n",
    "        val_targets.extend(batch[1].tolist())\n",
    "\n",
    "    test_targets = []\n",
    "    for batch in test_target_loader:\n",
    "        test_targets.extend(batch[1].tolist())\n",
    "\n",
    "    train_counts = [train_targets.count(i) for i in range(len(dataset.classes))]\n",
    "    val_counts = [val_targets.count(i) for i in range(len(dataset.classes))]\n",
    "    test_counts = [test_targets.count(i) for i in range(len(dataset.classes))]\n",
    "\n",
    "    print(\"Train class distribution:\", train_counts)\n",
    "    print(\"Val class distribution:\", val_counts)\n",
    "    print(\"Test class distribution:\", test_counts)"
   ],
   "metadata": {
    "id": "odhBcFF2zOTQ",
    "execution": {
     "iopub.status.busy": "2023-05-21T18:20:24.040892Z",
     "iopub.execute_input": "2023-05-21T18:20:24.041228Z",
     "iopub.status.idle": "2023-05-21T18:20:24.058443Z",
     "shell.execute_reply.started": "2023-05-21T18:20:24.041196Z",
     "shell.execute_reply": "2023-05-21T18:20:24.057559Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Convolutional block with two 3x3 convolutional layers followed by batch normalization layers and max pooling.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, hidden_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, hidden_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(hidden_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def conv_block(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Applies the convolutional block to the input tensor x.\"\"\"\n",
    "\n",
    "        return self.conv_block(x)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "   \"\"\"Residual block with two convolutions followed by batch normalization layers\"\"\"\n",
    "\n",
    "   def __init__(self, in_channels: int, hidden_channels: int,  out_channels: int):\n",
    "       super().__init__()\n",
    "       self.conv1 = nn.Conv2d(in_channels, hidden_channels, kernel_size=3, stride=1, padding=1)\n",
    "       self.bn1 = nn.BatchNorm2d(hidden_channels)\n",
    "\n",
    "       self.conv2 = nn.Conv2d(hidden_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "       self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "   def residual_block(self, x):\n",
    "       x1 = F.relu(self.bn1(self.conv1(x)))\n",
    "       x2 = F.relu(self.bn2(self.conv2(x1)))\n",
    "       return x2 + x\n",
    "\n",
    "   def forward(self, x): return self.residual_block(x)\n",
    "\n",
    "\n",
    "class LinearBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, after_conv: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(in_channels * 14 * 14, out_channels) if after_conv else nn.Linear(in_channels, out_channels)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def linear_block(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x): return self.linear_block(x)\n",
    "\n",
    "\n",
    "class ResModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ResModel, self).__init__()\n",
    "\n",
    "        self.conv1 = ConvBlock(3, 32, 32)\n",
    "        self.res1 = ResidualBlock(32, 32, 32)\n",
    "\n",
    "        self.conv2 = ConvBlock(32, 64, 64)\n",
    "        self.res2 = ResidualBlock(64, 64, 64)\n",
    "\n",
    "        self.conv3 = ConvBlock(64, 128, 128)\n",
    "        self.res3 = ResidualBlock(128, 128, 128)\n",
    "\n",
    "        self.conv4 = ConvBlock(128, 256, 256)\n",
    "        self.res4 = ResidualBlock(256, 256, 256)\n",
    "\n",
    "        # self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = LinearBlock(256, 512, after_conv=True)\n",
    "        self.fc2 = LinearBlock(512, 512)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Conv blocks\n",
    "        x = self.conv1(x)\n",
    "        x = self.res1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.res2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.res3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.res4(x)\n",
    "\n",
    "        # Linear blocks\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ],
   "metadata": {
    "id": "ySjINFZ67LjR",
    "execution": {
     "iopub.status.busy": "2023-05-21T18:20:24.059798Z",
     "iopub.execute_input": "2023-05-21T18:20:24.060136Z",
     "iopub.status.idle": "2023-05-21T18:20:24.082588Z",
     "shell.execute_reply.started": "2023-05-21T18:20:24.060104Z",
     "shell.execute_reply": "2023-05-21T18:20:24.081651Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Config\n",
    "\n",
    "root_dir = '/kaggle/input/crop-diseases/data/plant_dataset_original/plant_diseases_images'\n",
    "model_storage_dir = '/kaggle/output/models_storage'\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 6\n",
    "seed = 255\n",
    "\n",
    "adamax_lr = 0.001\n",
    "adamax_weight_decay = 0.001\n",
    "\n",
    "torch.manual_seed(seed)"
   ],
   "metadata": {
    "id": "O1no3eWTzOTR",
    "execution": {
     "iopub.status.busy": "2023-05-21T18:20:24.083938Z",
     "iopub.execute_input": "2023-05-21T18:20:24.084272Z",
     "iopub.status.idle": "2023-05-21T18:20:24.104516Z",
     "shell.execute_reply.started": "2023-05-21T18:20:24.084240Z",
     "shell.execute_reply": "2023-05-21T18:20:24.103450Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "execution_count": 8,
     "output_type": "execute_result",
     "data": {
      "text/plain": "<torch._C.Generator at 0x79b5d86e35d0>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "if not os.path.exists(model_storage_dir + '/saved_models'):\n",
    "    os.makedirs(model_storage_dir + '/saved_models')\n",
    "    \n",
    "if not os.path.exists(model_storage_dir + '/best_model_state'):\n",
    "    os.makedirs(model_storage_dir + '/best_model_state')\n",
    "    \n",
    "if not os.path.exists(model_storage_dir + '/curr_model_state'):\n",
    "    os.makedirs(model_storage_dir + '/curr_model_state')\n",
    "    \n",
    "if not os.path.exists(model_storage_dir + '/export_models'):\n",
    "    os.makedirs(model_storage_dir + '/export_models')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-21T18:25:13.708807Z",
     "iopub.execute_input": "2023-05-21T18:25:13.709262Z",
     "iopub.status.idle": "2023-05-21T18:25:13.718392Z",
     "shell.execute_reply.started": "2023-05-21T18:25:13.709226Z",
     "shell.execute_reply": "2023-05-21T18:25:13.717445Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Train\n",
    "\n",
    "best_val_acc = 0.0\n",
    "loss = None\n",
    "\n",
    "train_per_epoch = int(len(train_dataset) / batch_size)\n",
    "for e in range(epochs):\n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=True)\n",
    "    model.train()\n",
    "\n",
    "    train_acc = 0\n",
    "    train_losses = []\n",
    "    for idx, (images, labels) in loop:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(images)\n",
    "        loss = loss_fn(output, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        writer.add_scalar('loss', loss.item(), (e * train_per_epoch) + idx)\n",
    "\n",
    "        predictions = output.argmax(dim=1, keepdims=True).squeeze()\n",
    "        correct = (predictions == labels).sum().item()\n",
    "        accuracy = correct / len(predictions)\n",
    "\n",
    "        loop.set_description(f\"Epoch [{e}/{epochs}]\")\n",
    "        loop.set_postfix(loss=loss.item(), acc=accuracy)\n",
    "        writer.add_scalar('acc', accuracy, (e * train_per_epoch) + idx)\n",
    "\n",
    "        train_acc += correct\n",
    "        train_losses.append(loss.item())\n",
    "    else:\n",
    "        torch.save({\n",
    "            'epoch': e,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss.item(),\n",
    "        }, model_storage_dir + '/curr_model_state/last_train_model_state.pth')\n",
    "\n",
    "    train_acc /= len(train_dataset)\n",
    "    train_loss = np.array(train_losses).mean()\n",
    "    print(f'Epoch [{e}/{epochs}]: Train accuracy = {train_acc:.4f} Validation loss: {train_loss:.4f}')\n",
    "\n",
    "    scheduler.step()\n",
    "    # print(scheduler.get_last_lr()[0])\n",
    "\n",
    "    val_acc = 0.0\n",
    "    val_losses = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            val_loss = loss_fn(scores, y)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "            _, predictions = scores.max(1)\n",
    "            val_acc += (predictions == y).sum().item()\n",
    "\n",
    "    val_acc /= len(val_dataset)\n",
    "    val_loss = np.array(val_losses).mean()\n",
    "    print(f'Epoch [{e}/{epochs}]: Validation accuracy = {val_acc:.4f} Validation loss: {val_loss:.4f}')\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': e,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss.item()\n",
    "        }, model_storage_dir + '/curr_model_state/last_best_val_epoch_model_state.pth')"
   ],
   "metadata": {
    "id": "sbpegjkQzOTS",
    "outputId": "a3073142-9356-42d4-e780-ccda1267a285",
    "execution": {
     "iopub.status.busy": "2023-05-21T17:40:01.504630Z",
     "iopub.execute_input": "2023-05-21T17:40:01.505031Z",
     "iopub.status.idle": "2023-05-21T17:53:36.468610Z",
     "shell.execute_reply.started": "2023-05-21T17:40:01.504997Z",
     "shell.execute_reply": "2023-05-21T17:53:36.467408Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Test\n",
    "\n",
    "num_correct = 0\n",
    "num_samples = 0\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader: # images, labels\n",
    "        x = x.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "\n",
    "        scores = model(x)\n",
    "        _, predictions = scores.max(1)\n",
    "\n",
    "        num_correct += (predictions == y).sum()\n",
    "        num_samples += predictions.size(0)\n",
    "\n",
    "        y_true.extend(y.cpu().numpy())\n",
    "        y_pred.extend(predictions.cpu().numpy())\n",
    "\n",
    "    print(f'Model correctly predicted {num_correct} of total {num_samples} images with accuracy of'\n",
    "          f' {float(num_correct) / float(num_samples) * 100:.2f}%')"
   ],
   "metadata": {
    "id": "zuyZVSAOzOTS",
    "execution": {
     "iopub.status.busy": "2023-05-21T17:54:39.145249Z",
     "iopub.execute_input": "2023-05-21T17:54:39.145665Z",
     "iopub.status.idle": "2023-05-21T17:54:51.895106Z",
     "shell.execute_reply.started": "2023-05-21T17:54:39.145624Z",
     "shell.execute_reply": "2023-05-21T17:54:51.893813Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Analysis\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred, dataset.classes)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=dataset.classes, output_dict=True)\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df = df.drop(['support'], axis=1)\n",
    "sns.heatmap(df, annot=True, cmap='YlGnBu', fmt='.2f')\n",
    "plt.title('Classification Report Heatmap')\n",
    "plt.show()\n",
    "\n",
    "torch.save(model.state_dict(), model_storage_dir + '/saved_models/ResModel.pth')"
   ],
   "metadata": {
    "id": "abQ2rOcBzOTS",
    "execution": {
     "iopub.status.busy": "2023-05-21T17:58:34.293238Z",
     "iopub.execute_input": "2023-05-21T17:58:34.293658Z",
     "iopub.status.idle": "2023-05-21T17:58:35.254566Z",
     "shell.execute_reply.started": "2023-05-21T17:58:34.293626Z",
     "shell.execute_reply": "2023-05-21T17:58:35.253530Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
